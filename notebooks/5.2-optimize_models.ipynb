{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405f31e6-424a-498c-8380-df576a47592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "#                                 _             _      \n",
    "#                                | |_  ___ _ __(_)__ _ \n",
    "#                                | ' \\/ -_) '_ \\ / _` |\n",
    "#                                |_||_\\___| .__/_\\__,_|\n",
    "#                                         |_|          \n",
    "#\n",
    "#---------------------------------------------------------------------------------\n",
    "#\n",
    "# Company: HEPIA // HES-SO\n",
    "# Engineer: Hugo Varenne <hugo.varenne@master.hes-so.ch>\n",
    "# \n",
    "# Project Name: Unleashing the Full Potential of \n",
    "#               High-Performance Cherenkov Telescopes\n",
    "#               with Fully-Digital Solid-State Sensors Camera\n",
    "#\n",
    "# File: 5.2_optimize_models.ipynb\n",
    "# Description: Notebook for optimizing ctlearn models\n",
    "#\n",
    "# Last update: 2025-10-02\n",
    "#\n",
    "#--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f962cdeb-7bcb-45d3-9dfe-be2e5b81c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 09:51:42.438397: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 09:51:42.666132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-26 09:51:42.666168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-26 09:51:42.667209: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-26 09:51:42.747830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-26 09:51:48,125 | INFO | Logging initialized. All stdout/stderr will go to SLURM log.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import glob\n",
    "import shutil\n",
    "import hdf5plugin, h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from ctapipe.io import EventSource\n",
    "from sklearn import metrics\n",
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import json\n",
    "from ctlearn.tools.predict_model import MonoPredictCTLearnModel\n",
    "from ctlearn.utils import validate_trait_dict\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "from tools.train_model import TrainCTLearnModel\n",
    "from ctlearn.core.model import CTLearnModel\n",
    "from ctapipe.core.traits import ComponentName\n",
    "from traitlets.config import Config\n",
    "import yaml\n",
    "# Custom tools\n",
    "tools_path = os.path.join(\"../tools\")\n",
    "if tools_path not in sys.path:\n",
    "    sys.path.append(tools_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0e7f81-6002-43e1-afdd-4c64b63535e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths shortcuts (configurable in a yaml file)\n",
    "import tools.CTLearnMgrConfig as CTLearnMgrConfig\n",
    "importlib.reload(CTLearnMgrConfig)\n",
    "\n",
    "ctlearn_mgr_config = CTLearnMgrConfig.CTLearnMgrConfig()\n",
    "ctlearn_mgr_config.load_config('../config/ctlearnmgr_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264e65dc-1f36-45f6-80ce-7a33ae6f5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of model you wanna create : [\"type\", \"energy\", \"direction\"]\n",
    "RECO = \"energy\"\n",
    "\n",
    "# Name of the model (should match config name) [\"ResNet\", \"SimpleCNN\", \"LoadedModel\"] are the types of models\n",
    "loading = \"ResNet\"\n",
    "\n",
    "# Custom model config path \n",
    "config_filename = f\"{RECO}_{loading}_optimize.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd963ab-e65b-4ef6-80d7-7cd7859b0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_path = os.path.join(ctlearn_mgr_config.workspace_path, \"models\", \"configs\", config_filename)\n",
    "\n",
    "def recursive_config(d):\n",
    "    \"\"\"Recursively convert nested dicts into traitlets Configs.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        cfg = Config()\n",
    "        for k, v in d.items():\n",
    "            cfg[k] = recursive_config(v)\n",
    "        return cfg\n",
    "    return d\n",
    "    \n",
    "with open(config_path) as f:\n",
    "    yaml_config = yaml.safe_load(f)\n",
    "c = recursive_config(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c657955-7948-47c0-882e-09be899c8003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CTLearn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " ThinResNet_block (Function  (None, 1024)              5357600   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " fc_energy_1 (Dense)         (None, 512)               524800    \n",
      "                                                                 \n",
      " fc_energy_2 (Dense)         (None, 256)               131328    \n",
      "                                                                 \n",
      " energy (Dense)              (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6013985 (22.94 MB)\n",
      "Trainable params: 6013985 (22.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check model CTLearn\n",
    "prepare_config = c.prepare_model\n",
    "model = CTLearnModel.from_name(\n",
    "    prepare_config.model_type, \n",
    "    input_shape=tuple(prepare_config.input_shape), \n",
    "    tasks=prepare_config.tasks, \n",
    "    config=prepare_config\n",
    "    ).model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431d67a6-8c55-49b5-9d19-b4451faff584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ThinResNet_block\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 2)]          0         []                            \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 48)           144       ['input[0][0]']               \n",
      " ck1_1_conv (Conv2D)                                                                              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 48)           20784     ['ThinResNet_block_conv2_block\n",
      " ck1_2_conv (Conv2D)                                                1_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          576       ['input[0][0]']               \n",
      " ck1_0_conv (Conv2D)                                                                              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          9408      ['ThinResNet_block_conv2_block\n",
      " ck1_3_conv (Conv2D)                                                1_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          0         ['ThinResNet_block_conv2_block\n",
      " ck1_add (Add)                                                      1_0_conv[0][0]',              \n",
      "                                                                     'ThinResNet_block_conv2_block\n",
      "                                                                    1_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          0         ['ThinResNet_block_conv2_block\n",
      " ck1_out (ReLU)                                                     1_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 48)           9264      ['ThinResNet_block_conv2_block\n",
      " ck2_1_conv (Conv2D)                                                1_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 48)           20784     ['ThinResNet_block_conv2_block\n",
      " ck2_2_conv (Conv2D)                                                2_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          9408      ['ThinResNet_block_conv2_block\n",
      " ck2_3_conv (Conv2D)                                                2_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          0         ['ThinResNet_block_conv2_block\n",
      " ck2_add (Add)                                                      1_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv2_block\n",
      "                                                                    2_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv2_blo  (None, 96, 96, 192)          0         ['ThinResNet_block_conv2_block\n",
      " ck2_out (ReLU)                                                     2_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           18528     ['ThinResNet_block_conv2_block\n",
      " ck1_1_conv (Conv2D)                                                2_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           83040     ['ThinResNet_block_conv3_block\n",
      " ck1_2_conv (Conv2D)                                                1_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          74112     ['ThinResNet_block_conv2_block\n",
      " ck1_0_conv (Conv2D)                                                2_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          37248     ['ThinResNet_block_conv3_block\n",
      " ck1_3_conv (Conv2D)                                                1_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck1_add (Add)                                                      1_0_conv[0][0]',              \n",
      "                                                                     'ThinResNet_block_conv3_block\n",
      "                                                                    1_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck1_out (ReLU)                                                     1_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           36960     ['ThinResNet_block_conv3_block\n",
      " ck2_1_conv (Conv2D)                                                1_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           83040     ['ThinResNet_block_conv3_block\n",
      " ck2_2_conv (Conv2D)                                                2_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          37248     ['ThinResNet_block_conv3_block\n",
      " ck2_3_conv (Conv2D)                                                2_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck2_add (Add)                                                      1_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv3_block\n",
      "                                                                    2_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck2_out (ReLU)                                                     2_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           36960     ['ThinResNet_block_conv3_block\n",
      " ck3_1_conv (Conv2D)                                                2_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 96)           83040     ['ThinResNet_block_conv3_block\n",
      " ck3_2_conv (Conv2D)                                                3_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          37248     ['ThinResNet_block_conv3_block\n",
      " ck3_3_conv (Conv2D)                                                3_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck3_add (Add)                                                      2_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv3_block\n",
      "                                                                    3_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv3_blo  (None, 48, 48, 384)          0         ['ThinResNet_block_conv3_block\n",
      " ck3_out (ReLU)                                                     3_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          49280     ['ThinResNet_block_conv3_block\n",
      " ck1_1_conv (Conv2D)                                                3_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          147584    ['ThinResNet_block_conv4_block\n",
      " ck1_2_conv (Conv2D)                                                1_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          197120    ['ThinResNet_block_conv3_block\n",
      " ck1_0_conv (Conv2D)                                                3_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          66048     ['ThinResNet_block_conv4_block\n",
      " ck1_3_conv (Conv2D)                                                1_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck1_add (Add)                                                      1_0_conv[0][0]',              \n",
      "                                                                     'ThinResNet_block_conv4_block\n",
      "                                                                    1_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck1_out (ReLU)                                                     1_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          65664     ['ThinResNet_block_conv4_block\n",
      " ck2_1_conv (Conv2D)                                                1_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          147584    ['ThinResNet_block_conv4_block\n",
      " ck2_2_conv (Conv2D)                                                2_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          66048     ['ThinResNet_block_conv4_block\n",
      " ck2_3_conv (Conv2D)                                                2_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck2_add (Add)                                                      1_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv4_block\n",
      "                                                                    2_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck2_out (ReLU)                                                     2_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          65664     ['ThinResNet_block_conv4_block\n",
      " ck3_1_conv (Conv2D)                                                2_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 128)          147584    ['ThinResNet_block_conv4_block\n",
      " ck3_2_conv (Conv2D)                                                3_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          66048     ['ThinResNet_block_conv4_block\n",
      " ck3_3_conv (Conv2D)                                                3_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck3_add (Add)                                                      2_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv4_block\n",
      "                                                                    3_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv4_blo  (None, 24, 24, 512)          0         ['ThinResNet_block_conv4_block\n",
      " ck3_out (ReLU)                                                     3_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          131328    ['ThinResNet_block_conv4_block\n",
      " ck1_1_conv (Conv2D)                                                3_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          590080    ['ThinResNet_block_conv5_block\n",
      " ck1_2_conv (Conv2D)                                                1_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         525312    ['ThinResNet_block_conv4_block\n",
      " ck1_0_conv (Conv2D)                                                3_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         263168    ['ThinResNet_block_conv5_block\n",
      " ck1_3_conv (Conv2D)                                                1_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck1_add (Add)                                                      1_0_conv[0][0]',              \n",
      "                                                                     'ThinResNet_block_conv5_block\n",
      "                                                                    1_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck1_out (ReLU)                                                     1_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          262400    ['ThinResNet_block_conv5_block\n",
      " ck2_1_conv (Conv2D)                                                1_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          590080    ['ThinResNet_block_conv5_block\n",
      " ck2_2_conv (Conv2D)                                                2_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         263168    ['ThinResNet_block_conv5_block\n",
      " ck2_3_conv (Conv2D)                                                2_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck2_add (Add)                                                      1_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv5_block\n",
      "                                                                    2_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck2_out (ReLU)                                                     2_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          262400    ['ThinResNet_block_conv5_block\n",
      " ck3_1_conv (Conv2D)                                                2_out[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 256)          590080    ['ThinResNet_block_conv5_block\n",
      " ck3_2_conv (Conv2D)                                                3_1_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         263168    ['ThinResNet_block_conv5_block\n",
      " ck3_3_conv (Conv2D)                                                3_2_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck3_add (Add)                                                      2_out[0][0]',                 \n",
      "                                                                     'ThinResNet_block_conv5_block\n",
      "                                                                    3_3_conv[0][0]']              \n",
      "                                                                                                  \n",
      " ThinResNet_block_conv5_blo  (None, 12, 12, 1024)         0         ['ThinResNet_block_conv5_block\n",
      " ck3_out (ReLU)                                                     3_add[0][0]']                 \n",
      "                                                                                                  \n",
      " ThinResNet_block_global_av  (None, 1024)                 0         ['ThinResNet_block_conv5_block\n",
      " gpool (GlobalAveragePoolin                                         3_out[0][0]']                 \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5357600 (20.44 MB)\n",
      "Trainable params: 5357600 (20.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "submodel = model.get_layer(\"ThinResNet_block\")\n",
    "submodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a84477a-32d5-43fd-8c0d-5cff2cd77cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2025-11-19 08:44:30,023 | WARNING | Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /home/hugo/TM/ml/models/energy/optimize/temp/assets\n",
      "2025-11-19 08:44:32,318 | INFO | Assets written to: /home/hugo/TM/ml/models/energy/optimize/temp/assets\n"
     ]
    }
   ],
   "source": [
    "# Save pruned model\n",
    "# model_for_pruning.save(prepare_config.temp_dir)\n",
    "model.save(prepare_config.temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07d602-165d-4650-a9bd-afc852a34ed5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Quantization - (old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa3292-9a07-4760-9398-a4c288de8f07",
   "metadata": {},
   "source": [
    "\n",
    "def flatten_functional_model(model):\n",
    "    \"\"\"\n",
    "    Rebuild a Keras Functional model in a flat way,\n",
    "    preserving skip connections, branching, Add/Concat,\n",
    "    and handling unhashable KerasTensors.\n",
    "    \"\"\"\n",
    "    if not isinstance(model, tf.keras.Model):\n",
    "        raise ValueError(\"Model must be a Keras Model\")\n",
    "    \n",
    "    # 1) Create new input tensors\n",
    "    if isinstance(model.input, list):\n",
    "        new_inputs = [tf.keras.Input(shape=t.shape[1:], name=f\"flat_input_{i}\") for i, t in enumerate(model.input)]\n",
    "        tensor_map = {t.ref(): new for t, new in zip(model.input, new_inputs)}\n",
    "    else:\n",
    "        new_inputs = tf.keras.Input(shape=model.input.shape[1:], name=\"flat_input\")\n",
    "        tensor_map = {model.input.ref(): new_inputs}\n",
    "\n",
    "    # 2) Iterate layers in order\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            continue  # already handled\n",
    "\n",
    "        # Map inputs\n",
    "        layer_inputs = layer.input\n",
    "        if isinstance(layer_inputs, list):\n",
    "            mapped_inputs = [tensor_map[t.ref()] for t in layer_inputs]\n",
    "        else:\n",
    "            mapped_inputs = tensor_map[layer_inputs.ref()]\n",
    "\n",
    "        # Call layer\n",
    "        layer_outputs = layer(mapped_inputs)\n",
    "\n",
    "        # Map outputs\n",
    "        if isinstance(layer_outputs, list):\n",
    "            for old, new in zip(layer.output, layer_outputs):\n",
    "                tensor_map[old.ref()] = new\n",
    "        else:\n",
    "            tensor_map[layer.output.ref()] = layer_outputs\n",
    "\n",
    "    # 3) Map outputs\n",
    "    if isinstance(model.output, list):\n",
    "        new_outputs = [tensor_map[t.ref()] for t in model.output]\n",
    "    else:\n",
    "        new_outputs = tensor_map[model.output.ref()]\n",
    "\n",
    "    # 4) Build new model\n",
    "    return tf.keras.Model(inputs=new_inputs, outputs=new_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a061d-7f36-472f-83ff-d51a1b5bcad3",
   "metadata": {},
   "source": [
    "def flatten_functional_model(model):\n",
    "    \"\"\"\n",
    "    Rebuild a Keras Functional model in a flat way,\n",
    "    preserving skip connections, branching, Add/Concat,\n",
    "    and handling unhashable KerasTensors.\n",
    "    \"\"\"\n",
    "    if not isinstance(model, tf.keras.Model):\n",
    "        raise ValueError(\"Model must be a Keras Model\")\n",
    "    \n",
    "    # 1) Create new input tensors\n",
    "    if isinstance(model.input, list):\n",
    "        new_inputs = [tf.keras.Input(shape=t.shape[1:], name=f\"flat_input_{i}\") for i, t in enumerate(model.input)]\n",
    "        tensor_map = {t.ref(): new for t, new in zip(model.input, new_inputs)}\n",
    "    else:\n",
    "        new_inputs = tf.keras.Input(shape=model.input.shape[1:], name=\"flat_input\")\n",
    "        tensor_map = {model.input.ref(): new_inputs}\n",
    "\n",
    "    # 2) Iterate layers in order\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            continue\n",
    "\n",
    "        # Map inputs\n",
    "        layer_inputs = layer.input\n",
    "        if isinstance(layer_inputs, list):\n",
    "            mapped_inputs = [tensor_map[t.ref()] for t in layer_inputs]\n",
    "        else:\n",
    "            mapped_inputs = tensor_map[layer_inputs.ref()]\n",
    "\n",
    "        # Call layer\n",
    "        layer_outputs = layer(mapped_inputs)\n",
    "\n",
    "        # Map outputs\n",
    "        if isinstance(layer_outputs, list):\n",
    "            for old, new in zip(layer.output, layer_outputs):\n",
    "                tensor_map[old.ref()] = new\n",
    "        else:\n",
    "            tensor_map[layer.output.ref()] = layer_outputs\n",
    "\n",
    "    # 3) Map outputs\n",
    "    if isinstance(model.output, list):\n",
    "        new_outputs = [tensor_map[t.ref()] for t in model.output]\n",
    "    else:\n",
    "        new_outputs = tensor_map[model.output.ref()]\n",
    "\n",
    "    # 4) Build new model\n",
    "    return tf.keras.Model(inputs=new_inputs, outputs=new_outputs)\n",
    "    \n",
    "def iterate(layer):\n",
    "    \"\"\"\n",
    "    Flatten a layer if it's a nested Functional model.\n",
    "    Otherwise, return the layer as-is.\n",
    "    \"\"\"\n",
    "    if isinstance(layer, tf.keras.Model) and not isinstance(layer, tf.keras.Sequential):\n",
    "        return flatten_functional_model(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072bbe09-76af-4a2c-badd-5ca7040f1855",
   "metadata": {},
   "source": [
    "from tensorflow_model_optimization.quantization.keras import QuantizeWrapper\n",
    "\n",
    "flatten_model = auto_flatten_nested_models(model.get_layer(\"ThinResNet_block\"))\n",
    "\n",
    "x = flatten_model(model.input)\n",
    "x = model.get_layer(\"fc_type_1\")(x)\n",
    "x = model.get_layer(\"fc_type_2\")(x)\n",
    "x = model.get_layer(\"type\")(x)\n",
    "outputs = model.get_layer(\"softmax\")(x)\n",
    "\n",
    "new_model = Model(inputs=model.input, outputs=outputs)\n",
    "import tensorflow_model_optimization as tfmot\n",
    "quantized_flat_model = tfmot.quantization.keras.quantize_model(new_model)\n",
    "\n",
    "quantized_flat_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93f677-994d-4fcc-9493-d8ef172be311",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "qmodel = quantize_model(flat_model)\n",
    "qmodel.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e9efc-f667-4bf9-bd8f-fd06f76cba48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Quantization - (with AutoQKeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e653a9af-1432-44ef-b1ec-8eb42173296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantizing layers: ['ThinResNet_block', 'fc_energy_1', 'fc_energy_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "\n",
    "cur_strategy = tf.distribute.get_strategy()\n",
    "custom_objects = {}\n",
    "quantization_config = {\n",
    "        \"kernel\": {\n",
    "                \"binary\": 1,\n",
    "                \"stochastic_binary\": 1,\n",
    "                \"ternary\": 2,\n",
    "                \"stochastic_ternary\": 2,\n",
    "                \"quantized_bits(2,1,1,alpha=1.0)\": 2,\n",
    "                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "                \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "                \"quantized_po2(4,1)\": 4\n",
    "        },\n",
    "        \"bias\": {\n",
    "                \"quantized_bits(4,0,1)\": 4,\n",
    "                \"quantized_bits(8,3,1)\": 8,\n",
    "                \"quantized_po2(4,8)\": 4\n",
    "        },\n",
    "        \"activation\": {\n",
    "                \"binary\": 1,\n",
    "                \"ternary\": 2,\n",
    "                \"quantized_relu_po2(4,4)\": 4,\n",
    "                \"quantized_relu(3,1)\": 3,\n",
    "                \"quantized_relu(4,2)\": 4,\n",
    "                \"quantized_relu(8,2)\": 8,\n",
    "                \"quantized_relu(8,4)\": 8,\n",
    "                \"quantized_relu(16,8)\": 16\n",
    "        },\n",
    "        \"linear\": {\n",
    "                \"binary\": 1,\n",
    "                \"ternary\": 2,\n",
    "                \"quantized_bits(4,1)\": 4,\n",
    "                \"quantized_bits(8,2)\": 8,\n",
    "                \"quantized_bits(16,10)\": 16\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "limit = {\n",
    "    \"Dense\": [8, 8, 4],\n",
    "    \"Conv2D\": [4, 8, 4],\n",
    "    \"DepthwiseConv2D\": [4, 8, 4],\n",
    "    \"Activation\": [4],\n",
    "    \"BatchNormalization\": []\n",
    "}\n",
    "\n",
    "goal = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"int8\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\"\n",
    "        }\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "  \"output_dir\": \"../temp/\",\n",
    "  \"goal\": goal,\n",
    "  \"quantization_config\": quantization_config,\n",
    "  \"learning_rate_optimizer\": False,\n",
    "  \"transfer_weights\": False,\n",
    "  \"mode\": \"random\",\n",
    "  \"seed\": 42,\n",
    "  \"limit\": limit,\n",
    "  \"tune_filters\": \"layer\",\n",
    "  \"tune_filters_exceptions\": \"^dense\",\n",
    "  \"distribution_strategy\": cur_strategy,\n",
    "  # first layer is input, layer two layers are softmax and flatten\n",
    "  \"layer_indexes\": range(1, len(model.layers) - 1),\n",
    "  \"max_trials\": 20\n",
    "}\n",
    "\n",
    "print(\"quantizing layers:\", [model.layers[i].name for i in run_config[\"layer_indexes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f520ef8c-3ad2-42ed-a2ed-cc0b91fb4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100596.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100576.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100591.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100518.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100599.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100555.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_110056.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100589.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100593.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100581.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_110051.corsika.gz.NSBmed4.simtel.h5'), PosixPath('/home/hugo/TM/data/samples/gamma/train/gamma_200_800E3GeV_20_20deg_ATM52_100506.corsika.gz.NSBmed4.simtel.h5')]\n",
      "2025-11-17 09:48:16,593 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:17,084 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:17,483 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-17 09:48:17,590 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:17,696 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-17 09:48:17,802 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:17,912 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-17 09:48:18,013 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:18,119 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-17 09:48:18,224 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 09:48:18,334 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-17 09:48:18,445 | WARNING | MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dl1_data_handler.reader import DLDataReader\n",
    "from ctlearn.core.loader import DLDataLoader\n",
    "from ctlearn.core.model import CTLearnModel\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "training_config = c.training_model\n",
    "\n",
    "input_url_signal = []\n",
    "input_dir_signal = Path(training_config.TrainCTLearnModel.input_dir_signal)\n",
    "input_url_background = []\n",
    "\n",
    "file_pattern_signal = training_config.TrainCTLearnModel.file_pattern_signal\n",
    "\n",
    "for signal_pattern in file_pattern_signal:\n",
    "    input_url_signal.extend(input_dir_signal.glob(signal_pattern))\n",
    "\n",
    "dl1dh_reader = DLDataReader.from_name(\n",
    "    \"DLImageReader\",\n",
    "    input_url_signal=sorted(input_url_signal),\n",
    "    input_url_background=sorted(input_url_background)\n",
    ")\n",
    "indices = list(range(dl1dh_reader._get_n_events()))\n",
    "np.random.shuffle(indices)\n",
    "n_validation_examples = int(0.2 * dl1dh_reader._get_n_events())\n",
    "training_indices = indices[n_validation_examples:]\n",
    "validation_indices = indices[:n_validation_examples]\n",
    "\n",
    "training_loader = DLDataLoader(\n",
    "    dl1dh_reader,\n",
    "    training_indices,\n",
    "    tasks=[training_config.TrainCTLearnModel.reco_tasks],\n",
    "    batch_size=training_config.TrainCTLearnModel.batch_size,\n",
    "    random_seed=0,\n",
    "    sort_by_intensity=False,\n",
    "    stack_telescope_images=False,\n",
    ")\n",
    "validation_loader = DLDataLoader(\n",
    "    dl1dh_reader,\n",
    "    validation_indices,\n",
    "    tasks=[training_config.TrainCTLearnModel.reco_tasks],\n",
    "    batch_size=training_config.TrainCTLearnModel.batch_size,\n",
    "    random_seed=0,\n",
    "    sort_by_intensity=False,\n",
    "    stack_telescope_images=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab906d3c-40af-4815-afec-37c4196c9239",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoqk \u001b[38;5;241m=\u001b[39m \u001b[43mAutoQKeras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m autoqk\u001b[38;5;241m.\u001b[39mfit(training_loader, validation_data\u001b[38;5;241m=\u001b[39mvalidation_loader, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ctlearn/lib/python3.10/site-packages/qkeras/autoqkeras/autoqkeras_internal.py:832\u001b[0m, in \u001b[0;36mAutoQKeras.__init__\u001b[0;34m(self, model, metrics, custom_objects, goal, output_dir, mode, custom_tuner, transfer_weights, frozen_layers, activation_bits, limit, tune_filters, tune_filters_exceptions, learning_rate_optimizer, layer_indexes, quantization_config, overwrite, head_name, score_metric, **tuner_kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metrics:\n\u001b[1;32m    830\u001b[0m   metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoQKHyperModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransfer_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrozen_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrozen_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_filters_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune_filters_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# right now we create unique results directory\u001b[39;00m\n\u001b[1;32m    847\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ctlearn/lib/python3.10/site-packages/qkeras/autoqkeras/autoqkeras_internal.py:126\u001b[0m, in \u001b[0;36mAutoQKHyperModel.__init__\u001b[0;34m(self, model, metrics, custom_objects, target, transfer_weights, frozen_layers, activation_bits, limit, tune_filters, tune_filters_exceptions, layer_indexes, learning_rate_optimizer, head_name, quantization_config, extend_model_metrics)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;28;01mif\u001b[39;00m custom_objects \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransfer_weights \u001b[38;5;241m=\u001b[39m transfer_weights\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrozen_layers \u001b[38;5;241m=\u001b[39m frozen_layers \u001b[38;5;28;01mif\u001b[39;00m frozen_layers \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/miniforge3/envs/ctlearn/lib/python3.10/site-packages/qkeras/autoqkeras/forgiving_metrics/forgiving_energy.py:113\u001b[0m, in \u001b[0;36mForgivingFactorPower.get_reference\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress\n\u001b[0;32m--> 113\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mrun_qtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQTools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_quantizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreference_internal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreference_internal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_accumulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreference_accumulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfor_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m energy_dict \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mpe(\n\u001b[1;32m    123\u001b[0m     weights_on_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters_on_memory[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    124\u001b[0m     activations_on_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations_on_memory[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    125\u001b[0m     min_sram_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_sram_size[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    126\u001b[0m     rd_wr_on_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrd_wr_on_io[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_energy_dict \u001b[38;5;241m=\u001b[39m energy_dict\n",
      "File \u001b[0;32m~/miniforge3/envs/ctlearn/lib/python3.10/site-packages/qkeras/qtools/run_qtools.py:56\u001b[0m, in \u001b[0;36mQTools.__init__\u001b[0;34m(self, model, process, source_quantizers, is_inference, weights_path, keras_quantizer, keras_accumulator, for_reference)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# qgraph.PrintGraph(graph)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m qgraph\u001b[38;5;241m.\u001b[39mGraphPropagateActivationsToEdges(graph)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_map \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_layer_data_type_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_layer_data_type_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_quantizer_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_accumulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dict \u001b[38;5;241m=\u001b[39m interface\u001b[38;5;241m.\u001b[39mmap_to_json(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_map)\n",
      "File \u001b[0;32m~/miniforge3/envs/ctlearn/lib/python3.10/site-packages/qkeras/qtools/generate_layer_data_type_map.py:760\u001b[0m, in \u001b[0;36mgenerate_layer_data_type_map\u001b[0;34m(graph, source_quantizer_list, is_inference, keras_quantizer, keras_accumulator, for_reference, debug)\u001b[0m\n\u001b[1;32m    744\u001b[0m   layer_data_type_map[layer] \u001b[38;5;241m=\u001b[39m LayerDataType(\n\u001b[1;32m    745\u001b[0m       input_quantizer_list,\n\u001b[1;32m    746\u001b[0m       multiplier,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    754\u001b[0m       operation_count\n\u001b[1;32m    755\u001b[0m   )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node_type:\n\u001b[1;32m    758\u001b[0m   \u001b[38;5;66;03m# Any other unsupported layer types -> pass the input quantizer\u001b[39;00m\n\u001b[1;32m    759\u001b[0m   \u001b[38;5;66;03m# type to output in qraph\u001b[39;00m\n\u001b[0;32m--> 760\u001b[0m   (input_quantizer, _) \u001b[38;5;241m=\u001b[39m \u001b[43minput_qe_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    762\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m for_reference \u001b[38;5;129;01mand\u001b[39;00m keras_accumulator \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_input_layer:\n\u001b[1;32m    763\u001b[0m     input_quantizer \u001b[38;5;241m=\u001b[39m quantizer_factory\u001b[38;5;241m.\u001b[39mmake_default_quantizer(\n\u001b[1;32m    764\u001b[0m         mode\u001b[38;5;241m=\u001b[39mkeras_accumulator)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "autoqk = AutoQKeras(qmodel, metrics=[\"acc\"], custom_objects=custom_objects, **run_config)\n",
    "autoqk.fit(training_loader, validation_data=validation_loader, batch_size=1024, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd5e07-e347-4a36-8e88-71f8d2721cc4",
   "metadata": {},
   "source": [
    "### Quantization - (small tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf14ad8a-be65-422e-8a49-fade1ad8f9fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'quantize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'quantize'"
     ]
    }
   ],
   "source": [
    "quantized_model = model.quantize(\"int4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "124da709-7dc2-4b9a-9f5d-339e84d264cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.functional.Functional'>\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 94, 94, 18)        342       \n",
      "                                                                 \n",
      " act_1 (Activation)          (None, 94, 94, 18)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 92, 92, 32)        5216      \n",
      "                                                                 \n",
      " act_2 (Activation)          (None, 92, 92, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270848)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 270849    \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276407 (1.05 MB)\n",
      "Trainable params: 276407 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "TensorFlow version: 2.14.0\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 94, 94, 18)        342       \n",
      "                                                                 \n",
      " act_1 (Activation)          (None, 94, 94, 18)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 92, 92, 32)        5216      \n",
      "                                                                 \n",
      " act_2 (Activation)          (None, 92, 92, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270848)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 270849    \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276407 (1.05 MB)\n",
      "Trainable params: 276407 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from qkeras import *\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.utils import model_quantize, _add_supported_quantized_objects\n",
    "\n",
    "\n",
    "# Prepare custom_objects\n",
    "custom_objects = {}\n",
    "_add_supported_quantized_objects(custom_objects)\n",
    "\n",
    "# Register all QKeras objects for Keras serialization\n",
    "for name, obj in custom_objects.items():\n",
    "    keras.saving.register_keras_serializable(package=\"QKeras\", name=name)(obj)\n",
    "\n",
    "x = x_in = Input((96, 96, 2))\n",
    "x = Conv2D(18, (3, 3), name=\"conv2d_1\")(x)\n",
    "x = Activation(\"relu\", name=\"act_1\")(x)\n",
    "x = Conv2D(32, (3, 3), name=\"conv2d_2\")(x)\n",
    "x = Activation(\"relu\", name=\"act_2\")(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(1, name=\"dense\")(x)\n",
    "x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "print(type(model))\n",
    "model.summary()\n",
    "\n",
    "default_config = {\n",
    "    \"QConv2D\": {\n",
    "        \"conv2d_1\": {\n",
    "            \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "            \"bias_quantizer\": \"quantized_bits(4,0,1)\"\n",
    "        },\n",
    "        \"conv2d_2\": {\n",
    "            \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "            \"bias_quantizer\": \"quantized_bits(4,0,1)\"\n",
    "        }\n",
    "    },\n",
    "    \"QDense\": {\n",
    "        \"dense\": {\n",
    "            \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "            \"bias_quantizer\": \"quantized_bits(4)\"\n",
    "        }\n",
    "    },\n",
    "    \"default\": {\n",
    "        \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "        \"bias_quantizer\": \"quantized_bits(4,0,1)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "qmodel = model_quantize(\n",
    "    model,\n",
    "    default_config,\n",
    "    activation_bits=4,\n",
    "    transfer_weights=True,\n",
    "    custom_objects=custom_objects\n",
    ")\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d734196b-11bd-4fb5-a758-990a5f7d745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_18 InputLayer\n",
      "conv2d_1 Conv2D\n",
      "  activation: <function linear at 0x7645fca4a440>\n",
      "act_1 Activation\n",
      "  activation: <function relu at 0x7645fca49a20>\n",
      "conv2d_2 Conv2D\n",
      "  activation: <function linear at 0x7645fca4a440>\n",
      "act_2 Activation\n",
      "  activation: <function relu at 0x7645fca49a20>\n",
      "flatten Flatten\n",
      "dense Dense\n",
      "  activation: <function linear at 0x7645fca4a440>\n",
      "softmax Activation\n",
      "  activation: <function softmax at 0x7645fca49000>\n"
     ]
    }
   ],
   "source": [
    "for layer in qmodel.layers:\n",
    "    print(layer.name, layer.__class__.__name__)\n",
    "    if hasattr(layer, \"kernel_quantizer\"):\n",
    "        print(\"  kernel quantizer:\", layer.kernel_quantizer)\n",
    "    if hasattr(layer, \"bias_quantizer\"):\n",
    "        print(\"  bias quantizer:\", layer.bias_quantizer)\n",
    "    if hasattr(layer, \"activation\"):\n",
    "        print(\"  activation:\", layer.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffb14c11-23ce-407e-9fe2-a747df0afe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning, the weight is not quantized in the layer %s input_18\n",
      "warning, the weight is not quantized in the layer %s conv2d_1\n",
      "warning, the weight is not quantized in the layer %s act_1\n",
      "warning, the weight is not quantized in the layer %s conv2d_2\n",
      "warning, the weight is not quantized in the layer %s act_2\n",
      "warning, the weight is not quantized in the layer %s flatten\n",
      "warning, the weight is not quantized in the layer %s dense\n",
      "warning, the weight is not quantized in the layer %s softmax\n"
     ]
    }
   ],
   "source": [
    "for layer in qmodel.layers:\n",
    "  try:\n",
    "    if layer.get_quantizers():\n",
    "      q_w_pairs = zip(layer.get_quantizers(), layer.get_weights())\n",
    "      for _, (quantizer, weight) in enumerate(q_w_pairs):\n",
    "        qweight = K.eval(quantizer(weight))\n",
    "        print(\"quantized weight\")\n",
    "        print(qweight)\n",
    "  except AttributeError:\n",
    "    print(\"warning, the weight is not quantized in the layer %s\", layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab96d137-b5b3-4e25-acdd-c653bb20b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_18 InputLayer has_get_quantizers: False -> None\n",
      "1 conv2d_1 Conv2D has_get_quantizers: False -> None\n",
      "2 act_1 Activation has_get_quantizers: False -> None\n",
      "3 conv2d_2 Conv2D has_get_quantizers: False -> None\n",
      "4 act_2 Activation has_get_quantizers: False -> None\n",
      "5 flatten Flatten has_get_quantizers: False -> None\n",
      "6 dense Dense has_get_quantizers: False -> None\n",
      "7 softmax Activation has_get_quantizers: False -> None\n"
     ]
    }
   ],
   "source": [
    "inp_shape = qmodel.input_shape  # or model.inputs[0].shape\n",
    "dummy = np.zeros([1] + list(inp_shape[1:]), dtype=np.float32)\n",
    "_ = qmodel.predict(dummy, verbose=0)\n",
    "\n",
    "for i, L in enumerate(qmodel.layers):\n",
    "    has = hasattr(L, \"get_quantizers\")\n",
    "    q = None\n",
    "    if has:\n",
    "        try:\n",
    "            q = L.get_quantizers()\n",
    "        except Exception as e:\n",
    "            q = f\"get_quantizers() raised {e!r}\"\n",
    "    print(i, L.name, type(L).__name__, \"has_get_quantizers:\", has, \"->\", q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d704f-0b9f-44d5-94cf-b326136ce01b",
   "metadata": {},
   "source": [
    "### Quantization - last steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c69413d-8946-4a48-98b7-8734b6c8a909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.functional.Functional'>\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 94, 94, 18)        342       \n",
      "                                                                 \n",
      " act_1 (Activation)          (None, 94, 94, 18)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 92, 92, 32)        5216      \n",
      "                                                                 \n",
      " act_2 (Activation)          (None, 92, 92, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270848)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 270849    \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276407 (1.05 MB)\n",
      "Trainable params: 276407 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "x = x_in = Input((96, 96, 2))\n",
    "x = Conv2D(18, (3, 3), name=\"conv2d_1\")(x)\n",
    "x = Activation(\"relu\", name=\"act_1\")(x)\n",
    "x = Conv2D(32, (3, 3), name=\"conv2d_2\")(x)\n",
    "x = Activation(\"relu\", name=\"act_2\")(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(1, name=\"dense\")(x)\n",
    "x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "print(type(model))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe8999b8-c7ee-4b1c-a53f-b9e35ca0f956",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<Reference wrapping <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'ThinResNet_block')>>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 135\u001b[0m\n\u001b[1;32m    128\u001b[0m         q_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_apply(\n\u001b[1;32m    129\u001b[0m             annotated,\n\u001b[1;32m    130\u001b[0m             quantized_layer_name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquant_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_model\n\u001b[0;32m--> 135\u001b[0m annotated_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_full_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m annotated_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[30], line 125\u001b[0m, in \u001b[0;36mquantize_full_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquantize_full_model\u001b[39m(model):\n\u001b[0;32m--> 125\u001b[0m     annotated \u001b[38;5;241m=\u001b[39m \u001b[43mannotate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_scope():\n\u001b[1;32m    128\u001b[0m         q_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_apply(\n\u001b[1;32m    129\u001b[0m             annotated,\n\u001b[1;32m    130\u001b[0m             quantized_layer_name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquant_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[30], line 103\u001b[0m, in \u001b[0;36mannotate_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    101\u001b[0m     new_inbound \u001b[38;5;241m=\u001b[39m [tensor_map[t\u001b[38;5;241m.\u001b[39mref()] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inbound]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     new_inbound \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43minbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    105\u001b[0m annotated_layer \u001b[38;5;241m=\u001b[39m annotate_recursively(layer)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <Reference wrapping <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'ThinResNet_block')>>"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "\n",
    "def quantize_model(model):\n",
    "    editing_model = model\n",
    "    for i, layer in enumerate(editing_model.layers):\n",
    "        editing_model.layers[i] = annotate_layer(layer)\n",
    "    with tfmot.quantization.keras.quantize_scope():\n",
    "        q_aware_model = tfmot.quantization.keras.quantize_apply(editing_model, quantized_layer_name_prefix='quant_')\n",
    "    return q_aware_model\n",
    "    \n",
    "def annotate_layer(layer):\n",
    "    # If the layer is a nested model  recurse\n",
    "    if isinstance(layer, tf.keras.Model): \n",
    "        try:\n",
    "            nested_model = quantize_model(layer)\n",
    "            nested_model.summary()\n",
    "            return nested_model\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping model {layer.name}: {e}\")\n",
    "            return layer\n",
    "\n",
    "    # Skip layers that cannot be quantized\n",
    "    if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        return layer\n",
    "\n",
    "    # Wrap quantizable layers\n",
    "    try:\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(\n",
    "            layer\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping layer {layer.name}: {e}\")\n",
    "        return layer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "    \n",
    "annotated_model = quantize_model(model)\n",
    "annotated_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "15871568-9f56-4c80-b39a-140ad15d98bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Functional  (name: CTLearn_model)\n",
      "  - InputLayer  (name: input)\n",
      "  - Functional  (name: ThinResNet_block)\n",
      "    - InputLayer  (name: input)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block1_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block1_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block1_0_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block1_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv2_block1_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv2_block1_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block2_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block2_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv2_block2_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv2_block2_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv2_block2_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block1_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block1_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block1_0_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block1_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv3_block1_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv3_block1_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block2_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block2_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block2_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv3_block2_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv3_block2_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block3_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block3_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv3_block3_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv3_block3_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv3_block3_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block1_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block1_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block1_0_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block1_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv4_block1_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv4_block1_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block2_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block2_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block2_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv4_block2_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv4_block2_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block3_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block3_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv4_block3_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv4_block3_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv4_block3_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block1_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block1_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block1_0_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block1_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv5_block1_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv5_block1_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block2_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block2_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block2_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv5_block2_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv5_block2_out)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block3_1_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block3_2_conv)\n",
      "    - Conv2D  (name: ThinResNet_block_conv5_block3_3_conv)\n",
      "    - Add  (name: ThinResNet_block_conv5_block3_add)\n",
      "    - ReLU  (name: ThinResNet_block_conv5_block3_out)\n",
      "    - GlobalAveragePooling2D  (name: ThinResNet_block_global_avgpool)\n",
      "  - QuantizeWrapperV2  (name: quant_fc_energy_1)\n",
      "      [QUANTIZED]\n",
      "  - QuantizeWrapperV2  (name: quant_fc_energy_2)\n",
      "      [QUANTIZED]\n",
      "  - QuantizeWrapperV2  (name: quant_energy)\n",
      "      [QUANTIZED]\n"
     ]
    }
   ],
   "source": [
    "def print_quantization_tree(layer, indent=0):\n",
    "    prefix = \"  \" * indent\n",
    "    print(f\"{prefix}- {layer.__class__.__name__}  (name: {layer.name})\")\n",
    "\n",
    "    # If it's a wrapper  it's quantized\n",
    "    if \"QuantizeWrapper\" in layer.__class__.__name__:\n",
    "        print(f\"{prefix}    [QUANTIZED]\")\n",
    "\n",
    "    # Recurse for nested models\n",
    "    if isinstance(layer, tf.keras.Model):\n",
    "        for sub in layer.layers:\n",
    "            if sub is not layer:  # avoid self-loop\n",
    "                print_quantization_tree(sub, indent + 1)\n",
    "print_quantization_tree(annotated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94c7bcc7-a791-44f1-bccd-bf77dea9bdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CTLearn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " ThinResNet_block (Function  (None, 1024)              5357600   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " quant_fc_energy_1 (Quantiz  (None, 512)               524805    \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_fc_energy_2 (Quantiz  (None, 256)               131333    \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_energy (QuantizeWrap  (None, 1)                 262       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6014000 (22.94 MB)\n",
      "Trainable params: 6013985 (22.94 MB)\n",
      "Non-trainable params: 15 (60.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12869bb-1306-458c-97a5-91e4118a53bd",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "324d75b4-9903-4168-b4e3-2c9d4f944c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 440, in format\n",
      "    return self._format(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 436, in _format\n",
      "    return self._fmt % values\n",
      "KeyError: 'highlevel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ctapipe/core/logging.py\", line 52, in format\n",
      "    s = super().format(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 681, in format\n",
      "    s = self.formatMessage(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 650, in formatMessage\n",
      "    return self._style.format(record)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/logging/__init__.py\", line 442, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'highlevel'\n",
      "Call stack:\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_721/3629066728.py\", line 6, in <module>\n",
      "    model = TrainCTLearnModel(config=config_training)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/ctapipe/core/tool.py\", line 192, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/config/application.py\", line 442, in __init__\n",
      "    SingletonConfigurable.__init__(self, **kwargs)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/config/configurable.py\", line 116, in __init__\n",
      "    self.config = config\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1525, in notify_change\n",
      "    return self._notify_observers(change)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1568, in _notify_observers\n",
      "    c(event)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1143, in compatible_observer\n",
      "    return func(self, change)\n",
      "  File \"/home/hugo/miniforge3/envs/ctlearn/lib/python3.10/site-packages/traitlets/config/application.py\", line 457, in _config_changed\n",
      "    self.log.debug(\"Config changed: %r\", change.new)\n",
      "Message: 'Config changed: %r'\n",
      "Arguments: {'TrainCTLearnModel': {'output_dir': '/home/hugo/TM/ml/models/energy/optimize/v2/', 'input_dir_signal': '/home/hugo/TM/data/samples/gamma/train/', 'file_pattern_signal': ['gamma_*.h5'], 'model_type': 'LoadedModel', 'reco_tasks': 'energy', 'n_epochs': 1, 'batch_size': 128, 'overwrite': True, 'quiet': False, 'log_level': 'DEBUG', 'pruning_model': {'initial_sparsity': 0.5, 'final_sparsity': 0.9, 'begin_step': 0}}, 'CTLearnModel': {'attention_mechanism': None, 'attention_reduction_ratio': None, 'load_model_from': '/home/hugo/TM/ml/models/energy/optimize/temp/'}}\n",
      "2025-11-12 19:26:09,748 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.run): Starting: ctlearn-train-model\n",
      "2025-11-12 19:26:09,997 \u001b[1;33mWARNING\u001b[0m [tools.ctlearn-train-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n",
      "2025-11-12 19:26:09,998 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.initialize): Loading config from '[]'\n",
      "2025-11-12 19:26:10,000 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.initialize): ctapipe version 0.24.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "2025-11-12 19:26:10,002 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.setup): Number of devices: 1\n",
      "2025-11-12 19:26:10,004 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.setup): Loading data:\n",
      "2025-11-12 19:26:10,005 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.setup): For a large dataset, this may take a while...\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n",
      "2025-11-12 19:26:11,756 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.setup): Number of events loaded: 3236\n",
      "2025-11-12 19:26:11,757 \u001b[1;34mDEBUG\u001b[0m [tools.ctlearn-train-model] (tool.run): CONFIG: {'TrainCTLearnModel': {'batch_size': 128, 'config_files': [], 'dl1dh_reader_type': 'DLImageReader', 'early_stopping': None, 'file_pattern_background': ['*.h5'], 'file_pattern_signal': ['gamma_*.h5'], 'input_dir_background': None, 'input_dir_signal': PosixPath('/home/hugo/TM/data/samples/gamma/train'), 'log_config': {}, 'log_datefmt': '%Y-%m-%d %H:%M:%S', 'log_file': None, 'log_file_level': 'INFO', 'log_format': '[%(name)s]%(highlevel)s %(message)s', 'log_level': 10, 'logging_config': {}, 'lr_reducing': {'factor': 0.5, 'patience': 5, 'min_delta': 0.01, 'min_lr': 1e-06}, 'model_type': 'LoadedModel', 'n_epochs': 1, 'optimizer': {'name': 'Adam', 'base_learning_rate': 0.0001, 'adam_epsilon': 1e-08}, 'output_dir': PosixPath('/home/hugo/TM/ml/models/energy/optimize/v2'), 'overwrite': True, 'provenance_log': PosixPath('/home/hugo/TM/ml/ctlearn-train-model.provenance.log'), 'pruning_model': {'initial_sparsity': 0.5, 'final_sparsity': 0.9, 'begin_step': 0}, 'quiet': False, 'random_seed': 0, 'reco_tasks': ['energy'], 'save_best_validation_only': True, 'save_onnx': False, 'show_config': False, 'show_config_json': False, 'sort_by_intensity': False, 'stack_telescope_images': False, 'validation_split': 0.1, 'DLImageReader': {'allowed_tel_types': None, 'allowed_tels': None, 'channels': ['image', 'peak_time'], 'focal_length_choice': <FocalLengthKind.EFFECTIVE: 1>, 'force_dl1_lookup': False, 'image_mapper_type': [('type', '*', 'BilinearMapper')], 'min_telescopes': 1, 'min_telescopes_of_type': [('type', '*', 0)], 'mode': 'mono', 'skip_incompatible_files': False, 'TableQualityQuery': {'quality_criteria': [('> 50 phe', 'hillas_intensity > 50')]}}}}\n",
      "2025-11-12 19:26:11,758 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Setting up the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "2025-11-12 19:26:12,838 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Pruning CTLearn model.\n",
      "2025-11-12 19:26:12,839 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Pruning: steps_per_epoch=22, end_step=22 (n_epochs=1)\n",
      "2025-11-12 19:26:12,840 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Parameters for pruning: initial_sparsity=0.5, final_sparsity=0.9, begin_step=0\n",
      "2025-11-12 19:26:13,571 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Compiling CTLearn model.\n",
      "2025-11-12 19:26:13,580 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Training and evaluating...\n",
      "2025-11-12 19:26:13.750325: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2025-11-12 19:29:06.036328: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62816, saving model to /home/hugo/TM/ml/models/energy/optimize/v2/ctlearn_model.cpk\n",
      "INFO:tensorflow:Assets written to: /home/hugo/TM/ml/models/energy/optimize/v2/ctlearn_model.cpk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hugo/TM/ml/models/energy/optimize/v2/ctlearn_model.cpk/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 191s - loss: 0.6659 - mae_energy: 0.6659 - val_loss: 0.6282 - val_mae_energy: 0.6282 - lr: 1.0000e-04 - 191s/epoch - 9s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 19:29:24,843 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.start): Training and evaluating finished succesfully!\n",
      "2025-11-12 19:29:24,844 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (train_model.finish): Tool is shutting down\n",
      "2025-11-12 19:29:24,846 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/gamma_200_800E3GeV_20_20deg_ATM52_100505.h5\n",
      "2025-11-12 19:29:24,846 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/gamma_200_800E3GeV_20_20deg_ATM52_110055.h5\n",
      "2025-11-12 19:29:24,847 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/gamma_200_800E3GeV_20_20deg_ATM52_100575.h5\n",
      "2025-11-12 19:29:24,847 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/proton_400_1300E3GeV_20_20deg_ATM52_206092.h5\n",
      "2025-11-12 19:29:24,848 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/proton_400_1300E3GeV_20_20deg_ATM52_206029.h5\n",
      "2025-11-12 19:29:24,848 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: /home/hugo/TM/ml/models/type/optimize/v2/predict/proton_400_1300E3GeV_20_20deg_ATM52_206075.h5\n",
      "2025-11-12 19:29:24,849 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: \n",
      "2025-11-12 19:29:24,849 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: \n",
      "2025-11-12 19:29:24,850 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): Output: \n",
      "2025-11-12 19:29:24,850 \u001b[1;34mDEBUG\u001b[0m [tools.ctlearn-train-model] (tool.write_provenance): PROVENANCE: 'Details about provenance is found in /home/hugo/TM/ml/ctlearn-train-model.provenance.log'\n",
      "2025-11-12 19:29:24,868 \u001b[1;32mINFO\u001b[0m [tools.ctlearn-train-model] (tool.run): Finished ctlearn-train-model\n",
      "2025-11-12 19:29:24,869 \u001b[1;34mDEBUG\u001b[0m [tools.ctlearn-train-model] (application.exit): Exiting application: ctlearn-train-model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    }
   ],
   "source": [
    "# Load model as Custom one...\n",
    "config_training = c.training_model\n",
    "if os.path.exists(config_training.TrainCTLearnModel.output_dir):\n",
    "    shutil.rmtree(config_training.TrainCTLearnModel.output_dir)\n",
    "    \n",
    "model = TrainCTLearnModel(config=config_training)\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    model.run()\n",
    "except SystemExit as e:\n",
    "    print(f\"Caught SystemExit ({e.code}, continuing...)\")\n",
    "end = time.time()\n",
    "training_time = (end - start) * 1000 # ms\n",
    "training_events = model.dl1dh_reader._get_n_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad3bb75-b31c-4f21-a536-edb362b5dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CTLearn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " ThinResNet_block (Function  (None, 1024)              10703969  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_fc_ene  (None, 512)               1049090   \n",
      " rgy_1 (PruneLowMagnitude)                                       \n",
      "                                                                 \n",
      " prune_low_magnitude_fc_ene  (None, 256)               262402    \n",
      " rgy_2 (PruneLowMagnitude)                                       \n",
      "                                                                 \n",
      " prune_low_magnitude_energy  (None, 1)                 515       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12015976 (45.84 MB)\n",
      "Trainable params: 6013985 (22.94 MB)\n",
      "Non-trainable params: 6001991 (22.90 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pruned_path = os.path.join(config_training.TrainCTLearnModel.output_dir, \"ctlearn_model.cpk\")\n",
    "with tfmot.sparsity.keras.prune_scope():\n",
    "    model_pruned = tf.keras.models.load_model(model_pruned_path)\n",
    "model_pruned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b13f746-b8e7-4714-9117-6b71a04a7aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CTLearn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 2)]       0         \n",
      "                                                                 \n",
      " ThinResNet_block (Function  (None, 1024)              5357600   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " fc_energy_1 (Dense)         (None, 512)               524800    \n",
      "                                                                 \n",
      " fc_energy_2 (Dense)         (None, 256)               131328    \n",
      "                                                                 \n",
      " energy (Dense)              (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6013985 (22.94 MB)\n",
      "Trainable params: 6013985 (22.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_pruned)\n",
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9b106-e8c5-4a06-a312-edbf70579991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export.save(os.path.join(config_training.TrainCTLearnModel.output_dir, \"ctlearn_model.cpk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9856ac74-b541-4251-985f-83ecbc82d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:36:54,372 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 938ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "2025-11-12 11:37:08,893 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 992ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "2025-11-12 11:37:20,635 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 1s/step\n",
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:37:34,721 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 994ms/step\n",
      "1/1 [==============================] - 1s 797ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:37:53,992 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 10s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 11:38:17,337 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 13s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions\n",
    "config_training = c.training_model\n",
    "# Prepare Prediction model\n",
    "model = os.path.join(config_training.TrainCTLearnModel.output_dir, \"ctlearn_model.cpk\")\n",
    " \n",
    "\n",
    "# Predict on every test file\n",
    "particles = [\"gamma\", \"proton\"]\n",
    "testing_events = 0\n",
    "inference_time_global = 0\n",
    "# Create result folder (clean if already existing)\n",
    "shutil.rmtree(os.path.join(config_training.TrainCTLearnModel.output_dir, \"predict\"), ignore_errors=True)\n",
    "os.makedirs(os.path.join(config_training.TrainCTLearnModel.output_dir, \"predict\"), exist_ok=True)\n",
    "for particle in particles: \n",
    "        directory = os.path.join(ctlearn_mgr_config.training_samples_path, particle, \"test\")\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".h5\"):\n",
    "                # Prepare new filename as output\n",
    "                predict_file = os.path.basename(filename).split(\".\", 1)[0]\n",
    "                input_url = os.path.join(directory, filename)\n",
    "                # Create results file\n",
    "                output_url = os.path.join(config_training.TrainCTLearnModel.output_dir, \"predict\", f\"{predict_file}.h5\")\n",
    "                # Launch the prediction\n",
    "                match config_training.TrainCTLearnModel.reco_tasks:\n",
    "                    case \"type\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_type_model_from=model, output_path=output_url)\n",
    "                    case \"energy\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_energy_model_from=model, output_path=output_url)\n",
    "                    case \"direction\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_direction_model_from=model, output_path=output_url)\n",
    "                    case _:\n",
    "                        print(\"ERROR\")\n",
    "                start = time.time()\n",
    "                try:\n",
    "                    model_predict.run()\n",
    "                except SystemExit as e:\n",
    "                    print(f\"Caught SystemExit ({e.code}, continuing...)\")\n",
    "                stop = time.time()\n",
    "                testing_events += model_predict.dl1dh_reader._get_n_events()\n",
    "                inference_time_global += (stop - start) * 1000 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9dd879-4b82-4685-a27c-2f1348e139e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference per event : 35.0832 ms\n",
      "Total time to test : 97.9172 s for 2791 events\n"
     ]
    }
   ],
   "source": [
    "inference_per_events_pruned = inference_time_global / testing_events\n",
    "print(f\"Inference per event : {inference_per_events_pruned:.4f} ms\")\n",
    "print(f\"Total time to test : {(inference_time_global / 1000):.4f} s for {testing_events} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89148ab-f09d-4239-a491-de7fd267ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:22:16,253 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 908ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:22:25,456 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 1s/step\n",
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:22:36,889 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:22:47,411 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 10s 1s/step\n",
      "1/1 [==============================] - 1s 865ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:23:06,048 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 16:23:24,951 \u001b[1;33mWARNING\u001b[0m [ctlearn.ctlearn-predict-mono-model] (loader._handle_unrecognized_alias): Unrecognized alias: 'f', it will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Observation Block ID != Simulation Run Identifier).  Using Simulation Run Identifier for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 14s 1s/step\n",
      "1/1 [==============================] - 1s 890ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output [astropy.utils.metadata.merge]\n",
      "WARNING:astropy:MergeConflictWarning: In merged column 'obs_id' the 'description' attribute does not match (Simulation Run Identifier != Observation Block ID).  Using Observation Block ID for merged output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SystemExit (0, continuing...)\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions\n",
    "\n",
    "# Prepare Prediction model\n",
    "model = os.path.join(c.TrainCTLearnModel.output_dir, \"ctlearn_model.cpk\")\n",
    " \n",
    "\n",
    "# Predict on every test file\n",
    "particles = [\"gamma\", \"proton\"]\n",
    "testing_events = 0\n",
    "inference_time_global = 0\n",
    "# Create result folder (clean if already existing)\n",
    "shutil.rmtree(os.path.join(c.TrainCTLearnModel.output_dir, \"predict\"), ignore_errors=True)\n",
    "os.makedirs(os.path.join(c.TrainCTLearnModel.output_dir, \"predict\"), exist_ok=True)\n",
    "for particle in particles: \n",
    "        directory = os.path.join(ctlearn_mgr_config.training_samples_path, particle, \"test\")\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".h5\"):\n",
    "                # Prepare new filename as output\n",
    "                predict_file = os.path.basename(filename).split(\".\", 1)[0]\n",
    "                input_url = os.path.join(directory, filename)\n",
    "                # Create results file\n",
    "                output_url = os.path.join(c.TrainCTLearnModel.output_dir, \"predict\", f\"{predict_file}.h5\")\n",
    "                # Launch the prediction\n",
    "                match c.TrainCTLearnModel.reco_tasks:\n",
    "                    case \"type\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_type_model_from=model, output_path=output_url)\n",
    "                    case \"energy\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_energy_model_from=model, output_path=output_url)\n",
    "                    case \"direction\":\n",
    "                        model_predict = MonoPredictCTLearnModel(input_url=input_url, load_direction_model_from=model, output_path=output_url)\n",
    "                    case _:\n",
    "                        print(\"ERROR\")\n",
    "                start = time.time()\n",
    "                try:\n",
    "                    model_predict.run()\n",
    "                except SystemExit as e:\n",
    "                    print(f\"Caught SystemExit ({e.code}, continuing...)\")\n",
    "                stop = time.time()\n",
    "                testing_events += model_predict.dl1dh_reader._get_n_events()\n",
    "                inference_time_global += (stop - start) * 1000 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a0a87f-4f68-4802-8249-a9a759923796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.611548925035535\n",
      "93809.83304977417\n",
      "2791\n"
     ]
    }
   ],
   "source": [
    "inference_per_events_pruned = inference_time_global / testing_events\n",
    "print(inference_per_events_pruned)\n",
    "print(inference_time_global)\n",
    "print(testing_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52313f9-48d6-4395-ab8d-b1263851eb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
